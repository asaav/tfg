\section*{Resumen}
\addcontentsline{toc}{section}{\protect\numberline{}Resumen}
En este trabajo de fin de grado se ha abordado el análisis, diseño e implementación de un sistema de visión por computador capaz de detectar e identificar a las jugadoras y al balón de un partido de volleyball. El sistema debe extraer datos del partido y exportarlos a un CSV, permitiendo análisis de estadísticas del partido con fines de \textit{scouting} tales como velocidades, posiciones, trayectorias del balón, golpeos, etc. 

Las imágenes usadas para este sistema serán proporcionadas por una cámara en vista cenital del pabellón, y el desarrollo se realizará utilizando Python, la librería de visión por computador OpenCV, así como PyQt para la interfaz gráfica.

Los objetivos principales del proyecto son, como hemos dicho, desarrollar un sistema de visión artificial capaz de detectar las jugadoras y el balón (este último de una manera robusta, distinguiéndolo de las jugadoras) de un partido de volleyball; asignarle a cada una de estas formas un número identificador, consistente entre frames y exportar los datos de los contornos detectados durante las jugadas a un archivo CSV, usando los números identificadores para etiquetar los contornos en el mismo. Dos problemas a valorar son la política de resolución de solapamientos entre dos contornos de la escena (jugadora-jugadora o balón-jugadora) y la detección de las jugadas del partido.

Para llevar a cabo nuestro propósito, hemos implementado y analizado una serie de algoritmos de sustracción de fondo, así como de seguimiento (\textit{tracking}). De ellos, los recomendados son MOG2 y Mean Shift, de acuerdo a criterios de selección basados en rendimiento y en calidad de la detección. Para detectar el balón, se le pasa un test de circularidad a los contornos detectados, que luego se usará en el algoritmo de consistencia temporal. Este algoritmo mejora la detección del balón al utilizar una serie de heurísticas que tienen en cuenta la posición del balón para marcarlo en la escena.

En conclusión, creemos que los objetivos del trabajo se han cumplido ampliamente. La delimitación automática de jugadas queda como una vía futura de ampliación del proyecto, solucionarlo requeriría de un estudio de ese problema en especifico. Los solapamientos se han solucionado combinando los dos contornos en uno solo. 


\newpage
\section*{Extended Abstract}
\addcontentsline{toc}{section}{\protect\numberline{}Extended Abstract}

In this end-of-degree project, we covered the analysis, design and implementation of a computer vision solution capable of detecting and tracking the players and the ball of a volleyball match. The videos we used for our purpose were taken using a top-down perspective camera installed in the Eduardo Linares high school’s sports hall. All the development was done in Python, using OpenCV, one of the most important libraries in computer vision. Also, we used PyQt for the graphical user interface, which is a user-friendly alternative to the console line parameter version. However, both versions have the same functionality. 

Computer vision is normally used to describe field that tries to make computers able to understand images and videos at a human level. Although this field works with computers, it is not just a matter of research for computer scientists: there are psychologists, opticians and several other scientific researchers actively searching for new algorithms and techniques to make computer vision as close to that of humans as possible. In its beginnings, the difficulty of computer vision was often underestimated, but nowadays it is considered as one of the main barriers in the way to a true AI. Proof of that underestimation is that in 1966, an MIT student was assigned a summer project which consisted in attaching a camera to a computer and making it describe in natural language what it saw on that camera. Later, the world of computer research began to realize the true difficulty inherent to the issue at hand.

Currently, there are plenty of computer vision solutions to a wide range of problems. In sports, for example, we can find Hawk-Eye, a popular computer vision system used mainly in tennis buy also in some other sports. In tennis, Hawk-Eye is used by referees and players to help determine if a ball was out of bounds or not. There are also solutions oriented to gather statistics useful for scouting purposes and coaching, like SportsVU, which uses images from multiple cameras to present statistics such as heat maps, possession maps, passing maps, etc. This system can be used in several sports, like basketball, football, rugby and some others. Our project, like SportsVU, has the aim to provide data to analysts. Lastly, we have solutions oriented to the audience, Intel 360 Replay is one of those. Again, this technology data from many cameras around the playing field (38 in the case of football) to provide 3D reconstructed replays of actions of the game.

We will now talk about the goals of our project. As we said, our main purpose is to provide an app capable of recognize and track the players and ball of a volleyball match, assign them an ID number and retrieve all the data referring their positions to store it in a human readable way, divided by plays, so it can be analysed later. Our system will use videos in a top-down perspective. Two aspects that we must pay close attention to are the separation between plays and the contour overlapping policy. The former should ideally be automatic, although, since it is a tough problem to solve, it could also be manual, for example using keys. As for the overlapping policy, when two players or a player and the ball come close, we will have a contour overlapping. For as long as they are overlapped, the two contours will be indistinguishable for the system, and when they separate, we will have to consider the option of giving them new IDs or try to give them the one that they had before overlapping. 

The tools we have used to develop this project are: 
\begin{itemize}
    \item Python, which we chose as a programming language due to its great expressiveness and ease which it provides to many things we needed to develop.
    \item PyQt to make a graphical user interface to make the final software more usable by the mean user providing the same functionality available in the console line version.
    \item OpenCV is the most important tool in this project, since it provided us with all the necessary functionality referring to computer vision algorithms and techniques.  
    \item Git is the last tool we used, it was very useful as a version control system that allowed me and my tutor to share my work for feedback very easily.
\end{itemize}

Now, we will detail the design and actual development of our project. To achieve our goal of detecting players and ball, we have two main options at hand: we can use tracking or background subtraction. Also, we could combine both of those methods into our software to make it more consistent and fault tolerant. The methodology we followed to build the software was to develop these parts separately and integrating them into the final version.

Background subtraction is a technique which consists on creating a background model for a scene, which helps to identify every object different of said background as foreground. Since the images we will use will always use the same perspective, a naïve approach to generating a background model to our scene would be to use a frame of the pitch with no players in it and use a simple frame difference between that model and every frame of the video. Unfortunately, this method is extremely sensitive to lighting changes, and, due to its nature, incapable of detecting players’ shadows. Also, we won't always have the possibility of getting a frame without any objects in the scene, which makes it harder to create a background model just by saving a frame. Due to these reasons, this method isn’t as good as expected, so we will need to consider some others.

Fortunately, OpenCV provides us with many background subtraction algorithms. Some of those algorithms, with we later will discuss and compare, are MOG, MOG2, GMG, CNT, KNN and GSOC. We will implement all of them to compare how they perform in our application.

The first of those techniques, MOG, receives its name because it uses a mixture of k gaussians to generate a background model with $3 \leq k \leq 5$. The gaussians generated are ordered by a measure of their fitness, and for each new pixel, it is marked as foreground if it is more than 2.5 standard deviations over the distributions below certain probability threshold. MOG is an improvement over a previous algorithm, and one of the main innovations over that one is that it is capable of detecting shadows by using a chromatic representation of the frame, while also considering luminance.

MOG2 is, again, an improvement over its predecessor, MOG. The difference between them is that, while MOG maintains the same number of gaussians for every pixel of the frame, MOG2 adapts this number. This way, the more uniform the distribution of a region is, the less gaussians will the algorithm use, making it more efficient at little to no cost in effectiveness.

While both previous algorithms were semiparametric, GMG is non-parametric. It stores a histogram in RGB space for every pixel of the video, using the first frames of the video as a training set. Once generated said histogram, GMG uses Bayesian inference to determine whether a pixel is part of the background or not.

The next method, CNT (short from count), was developed with low specs systems in mid, like Raspberry Pi and similar. As its name suggests, the procedure of the algorithm is to count the stability over time of each pixel of the image. This way, the more stable a pixel remains throughout the video, the more probable is that said pixel is part of the background.

GSOC was developed during a Google Summer of Code, which it receives its name from. It is based on the algorithm LSBP. The documentation of the method doesn’t describe accurately how does it work, although they say it uses video-saliency. Nevertheless, the code is available on GitHub.

The last of the methods we compared is KNN, or the k-nearest neighbours algorithm is also non-parametric often used in general classification problems. KNN classifies points based on how their k nearest neighbours are classified. Applied to background subtraction, KNN initializes itself during the first frames of the video, considering everything on those starting frames as background, and then, it calculates distances from every new pixel to the RGB vectors stored previously. The election of k in this method is adaptative, using bigger values in regions with more density and smaller values in regions with small density.

We now needed to make a choice between the previous algorithms. Although the final software doesn’t really need to be in real time, we want to make it as fast as possible while sacrificing as less effectiveness as possible. Because of that, we made an analysis of performance of all these algorithms, where MOG2, CNT and KNN were the best performance-wise. CNT was discarded due to its inconsistency in detection and its difficulty to detect shadows properly. Between the last two, MOG2 was the selected because it generated better backgrounds models. 

After applying the background subtraction algorithm selected, we needed to perform some additional procedures to improve the results achieved using it. One of them is assigning every contour an ID number that identifies them both visually and in the CSV file generated after running the program. To make these assignments, we used a mutual matching algorithm between contours of a frame to those of the former.

Another of those procedures is non-maximum suppression, which consists in detecting overlapping contours and finding a maximum enclosure for them. This way, the detection of every contour is cleaner. A side effect to this operation is that, when two players overlap, the rectangles that identify them will also overlap, so they will join in a single rectangle until they separate. Therefore, our overlapping resolution policy will be to assign a new ID to the maximum rectangle which encloses both players and when they separate, assume they are two new contours. This is because determining which previous ID belongs to which player is very difficult, even if we use their paths, it is possible that a player changes direction after overlapping with another.

As stated before, we need to make the ball detection especially consistent, but to the eyes of our background subtractor, contours have no special distinction between them. To distinguish the ball apart from the players, we need a circularity test based in the shape of that contour. The roundest element of the scene must be the ball.

When implementing tracking algorithms, at the beginning we tested the ones included in the collaborative module of OpenCV, but they were all too slow and were discarded in favour of Mean Shift and Camshift. 

Both methods are roughly the same. The difference is that Camshift adapts the tracking window to the object that it is following. Apart from that, both methods store a histogram of the first tracking window provided and, from that point on, calculate back projections of the image over that histogram thus getting a probability map and then calculating the centroid of the points near the window until the algorithm converges. Between these two algorithms, we chose Mean Shift over Camshift because we don’t need our algorithm to adapt to shapes because they will always have the same size since their distances to the camera will be the same most of the time.

We still had to solve ball detection consistency. Until this point, we used a shape test over all the scene, which led the algorithm to momentarily mark players as ball when they were perpendicular to the camera and we also sometimes lost track of the ball, giving it a new ID. This could be solved by considering the ball’s last position, using temporal consistency. 

To implement this, first we needed to make the software able to detect plays, which we did manually as it is hard to determine when a play ends automatically without having a clear reference of the distance between the ball and the floor. Once we run the software once marking all the plays we want, we can run it again passing the log file generated with the data of said plays. Applying a group of heuristics, like distance from the last frame to the next, circularity value and taking into account the ID that was consecutively identified as ball more frames, we can take our software from a 22\% of ball detection to 78\% in the frames of a single play, which is a great improvement considering the ball doesn’t appear in every frame due to overlaps.

All things considered, this project concluded with a high level of accomplishment of the objectives we set ourselves. We developed a system that uses both background subtraction and tracking to detect the players of the scene. For ball detection, we used circularity test as well as temporal consistency using some heuristics. The final software has two interface options, one uses command line parameters and the other is a graphical user interface developed in PyQt with the intent of providing a friendlier user experience to some people.

Some ways that we could improve this project are implementing automatic play detection, extending the temporal consistency model to include also players, using other models like Hidden Markov Models, Kalman filters or Viterbi algorithm and solving the overlapping problems giving players their previous ID number. We also could consider parameter auto-tuning as a way to improve the application
